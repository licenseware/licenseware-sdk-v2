commonLabels:
  licenseware.io/app: { { trimSuffix "-service" .Chart.Name } }
  licenseware.io/env: prod
  licenseware.io/tier: backend
  licenseware.io/owner: licenseware

global: # will overwrite all the apps
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 2000m
      memory: 8Gi

  autoscaling: {}

  nodeSelector: {}

  tolerations: []

  affinity: {}

  topologySpreadConstraints:
    maxSkew: 1
    enabled: true
    topologyKey: node
    whenUnsatisfiable: DoNotSchedule

config:
  appHost: ""
  appId: ""
  appUriPrefix: "" # e.g. /ifmp

  persistence:
    claimName: "" # default: chart name
    enabled: true
    size: "5Gi"
    accessMode: ReadWriteMany
    storageClassName: efs

  mongo:
    databaseName: ""

  identity:
    user: ""

  fileUploadPath: /tmp/lware

  authService:
    url: ""

  registryService:
    url: ""

  redis:
    host: ""
    port: 6379

  worker:
    broker:
      uri: ""
      celeryConnectionMaxRetry: 3
    backend:
      uri: ""
    celeryDefaultTaskRateLimit: 10/s
    celeryTaskSerializer: json
    celeryTaskCompression: bzip2
    celeryConsumerOffset: latest

secret:
  identity:
    password: ""

  mongo:
    connectionString: ""

  redis:
    password: ""

image:
  repository: ""
  tag: ""
  pullPolicy: Always

imagePullSecrets: []

nameOverride: ""

fullnameOverride: ""

serviceAccount:
  create: true
  annotations: {}
  # If not set and create is true, a name is generated using the fullname template
  name: ""

podAnnotations: {}

podSecurityContext:
  {}
  # fsGroup: 2000

securityContext:
  {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000

dashboardApp:
  command: celery -A main:broker flower --address=0.0.0.0 --port={{ tpl .Values.dashboardApp.service.containerPort . }}

  healthCheckUri: "/" # e.g. /

  replicaCount: 1

  labels:
    {{- tpl (.Values.commonLabels | toYaml) . | indent 4 }}
    licenseware.io/type: dashboard

  service:
    enabled: true
    type: ClusterIP
    port: 80
    containerPort: 5000
    portName: http
    protocol: TCP

  ingress:
    enabled: false
    className: "nginx"
    annotations: {}
    hosts:
      - host: ""
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []

  resources: {}

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 70

  nodeSelector: {}

  tolerations: []

  affinity: {}

  probes:
    livenessProbe:
      tcpSocket:
        port: { { tpl .Values.dashboardApp.service.containerPort . } }
      initialDelaySeconds: 5
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 3
      periodSeconds: 10

    readinessProbe:
      httpGet:
        path: { { tpl .Values.dashboardApp.healthCheckUri . } }
        port: { { tpl .Values.dashboardApp.service.containerPort . } }
      initialDelaySeconds: 5
      timeoutSeconds: 5
      successThreshold: 1
      failureThreshold: 3
      periodSeconds: 10

  topologySpreadConstraints: {}

webApp:
  command: uwsgi -M --http-socket=0.0.0.0:{{ tpl .Values.webApp.service.containerPort }} -w main:app --processes=4 --enable-threads --threads=4

  healthCheckUri: "" # e.g. /ifmp/swagger.json

  replicaCount: 2

  service:
    type: ClusterIP
    port: 80
    containerPort: 5000
    protocol: TCP
    portName: http

  ingress:
    enabled: false
    className: "nginx"
    annotations:
      {}
      # kubernetes.io/ingress.class: nginx
      # kubernetes.io/tls-acme: "true"
    hosts:
      - host: ""
        paths:
          - path: /
            pathType: ImplementationSpecific
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

  resources: {}

  autoscaling:
    enabled: true
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80

  nodeSelector: {}

  tolerations: []

  affinity: {}

  topologySpreadConstraints: {}

workerApp:
  command: celery -A main:broker worker -l info -c 4 --autoscale=4,10

  replicaCount: 1

  resources: {}

  autoscaling:
    enabled: true
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    targetMemoryUtilizationPercentage: 70

  nodeSelector: {}

  tolerations: []

  affinity: {}

  topologySpreadConstraints: {}
